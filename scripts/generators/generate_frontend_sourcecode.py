#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‰ç«¯æºä»£ç æ‹¼æ¥è„šæœ¬
å°† output_sourcecode/front/ ç›®å½•ä¸‹æ‰€æœ‰HTMLæ–‡ä»¶å†…å®¹æ‹¼æ¥ç”Ÿæˆç»Ÿä¸€çš„å‰ç«¯æºä»£ç æ–‡æ¡£

CSSå¤„ç†ç­–ç•¥ï¼š
- å½»åº•ç§»é™¤ <style> æ ‡ç­¾åŠå…¶å†…å®¹
- ç§»é™¤ CSS å¤–éƒ¨é“¾æ¥ (rel="stylesheet")  
- ç§»é™¤å†…è”æ ·å¼å±æ€§ (style="...")
- ä¿ç•™HTMLç»“æ„å’ŒJavaScripté€»è¾‘
- ä¿ç•™classå±æ€§ï¼ˆå¯èƒ½å¯¹JavaScriptåŠŸèƒ½é‡è¦ï¼‰

è¿™æ ·å¯ä»¥æ˜¾è‘—å‡å°‘æ–‡æ¡£é•¿åº¦ï¼Œçªå‡ºæ ¸å¿ƒç¨‹åºé€»è¾‘ï¼Œæ›´é€‚åˆè½¯è‘—ç”³è¯·ææ–™è¦æ±‚
"""

import os
import re
import math

def remove_css_content(html_content):
    """
    å½»åº•ç§»é™¤HTMLä¸­çš„CSSæ ·å¼å†…å®¹ï¼Œåªä¿ç•™HTMLç»“æ„å’ŒJavaScripté€»è¾‘
    """
    # ç§»é™¤ <style> æ ‡ç­¾åŠå…¶å†…å®¹
    html_content = re.sub(r'<style[^>]*>.*?</style>', 
                         '\n    <!-- CSSæ ·å¼å·²çœç•¥ï¼Œå®Œæ•´CSSè¯·æŸ¥çœ‹åŸå§‹HTMLæ–‡ä»¶ -->\n', 
                         html_content, flags=re.DOTALL)
    
    # ç§»é™¤CSSå¤–éƒ¨é“¾æ¥ï¼ˆä¿ç•™JavaScriptå’Œå­—ä½“é“¾æ¥ï¼‰
    html_content = re.sub(r'<link[^>]*rel=["\']stylesheet["\'][^>]*>', 
                         '    <!-- CSSå¤–éƒ¨é“¾æ¥å·²çœç•¥ -->', 
                         html_content, flags=re.IGNORECASE)
    
    # ç§»é™¤å†…è”æ ·å¼å±æ€§
    html_content = re.sub(r'\s+style=["\'][^"\']*["\']', '', html_content)
    
    # ç§»é™¤CSSç›¸å…³çš„classå±æ€§ï¼ˆå¯é€‰ï¼Œä¿ç•™åŠŸèƒ½æ€§classï¼‰
    # è¿™é‡Œæˆ‘ä»¬ä¿ç•™classå±æ€§ï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½å¯¹JavaScriptåŠŸèƒ½é‡è¦
    
    return html_content

def estimate_tokens(text):
    """
    ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡ (ç²—ç•¥ä¼°ç®—ï¼š1 token â‰ˆ 4 ä¸ªå­—ç¬¦)
    """
    return len(text) // 4

def split_content_by_token_limit(html_files, front_dir, max_tokens=30000):
    """
    æ ¹æ®tokené™åˆ¶æ™ºèƒ½åˆ†æ‰¹HTMLæ–‡ä»¶
    """
    batches = []
    current_batch = []
    current_tokens = 0
    
    for html_file in html_files:
        file_path = os.path.join(front_dir, html_file)
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç§»é™¤CSSåä¼°ç®—tokenæ•°
            clean_content = remove_css_content(content)
            file_tokens = estimate_tokens(clean_content)
            
            # å¦‚æœå•ä¸ªæ–‡ä»¶å°±è¶…è¿‡é™åˆ¶ï¼Œéœ€è¦è¿›ä¸€æ­¥å¤„ç†
            if file_tokens > max_tokens:
                # å¦‚æœå½“å‰æ‰¹æ¬¡ä¸ä¸ºç©ºï¼Œå…ˆä¿å­˜
                if current_batch:
                    batches.append(current_batch)
                    current_batch = []
                    current_tokens = 0
                
                # å°†å¤§æ–‡ä»¶å•ç‹¬ä½œä¸ºä¸€ä¸ªæ‰¹æ¬¡ï¼ˆæˆ–è¿›ä¸€æ­¥æ‹†åˆ†ï¼‰
                batches.append([html_file])
                print(f"âš ï¸  æ–‡ä»¶ {html_file} è¾ƒå¤§ (~{file_tokens} tokens)ï¼Œå•ç‹¬å¤„ç†")
                continue
            
            # æ£€æŸ¥åŠ å…¥å½“å‰æ–‡ä»¶åæ˜¯å¦è¶…é™
            if current_tokens + file_tokens > max_tokens and current_batch:
                # ä¿å­˜å½“å‰æ‰¹æ¬¡ï¼Œå¼€å§‹æ–°æ‰¹æ¬¡
                batches.append(current_batch)
                current_batch = [html_file]
                current_tokens = file_tokens
            else:
                # åŠ å…¥å½“å‰æ‰¹æ¬¡
                current_batch.append(html_file)
                current_tokens += file_tokens
                
        except Exception as e:
            print(f"âš ï¸  è¯»å–æ–‡ä»¶ {html_file} æ—¶å‡ºé”™: {e}")
            current_batch.append(html_file)  # ä»ç„¶åŠ å…¥æ‰¹æ¬¡ï¼Œç¨åå¤„ç†
    
    # ä¿å­˜æœ€åä¸€ä¸ªæ‰¹æ¬¡
    if current_batch:
        batches.append(current_batch)
    
    return batches

def compress_html_content(html_content, compression_level=1):
    """
    è¿›ä¸€æ­¥å‹ç¼©HTMLå†…å®¹ä»¥å‡å°‘tokenæ•°é‡
    
    compression_level:
    1 - è½»åº¦å‹ç¼©ï¼šç§»é™¤å¤šä½™ç©ºç™½ï¼Œä¿ç•™ç»“æ„
    2 - ä¸­åº¦å‹ç¼©ï¼šç§»é™¤æ³¨é‡Šï¼Œç®€åŒ–æ ‡ç­¾
    3 - é‡åº¦å‹ç¼©ï¼šåªä¿ç•™æ ¸å¿ƒç»“æ„å’ŒJavaScript
    """
    if compression_level >= 1:
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å’Œæ¢è¡Œ
        html_content = re.sub(r'\n\s*\n', '\n', html_content)  # ç§»é™¤ç©ºè¡Œ
        html_content = re.sub(r'^\s+', '', html_content, flags=re.MULTILINE)  # ç§»é™¤è¡Œé¦–ç©ºç™½
        
    if compression_level >= 2:
        # ç§»é™¤HTMLæ³¨é‡Š
        html_content = re.sub(r'<!--[^>]*-->', '', html_content, flags=re.DOTALL)
        # ç§»é™¤å¤šä½™çš„æ ‡ç­¾å±æ€§ï¼ˆä¿ç•™é‡è¦çš„id, class, onclickç­‰ï¼‰
        # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦è¿›ä¸€æ­¥å®šåˆ¶
        
    if compression_level >= 3:
        # é‡åº¦å‹ç¼©ï¼šåªä¿ç•™æ ¸å¿ƒç»“æ„
        # ç§»é™¤å¤§éƒ¨åˆ†éåŠŸèƒ½æ€§å†…å®¹ï¼Œåªä¿ç•™å…³é”®çš„DOMç»“æ„å’ŒJavaScript
        html_content = re.sub(r'<meta[^>]*>', '', html_content, flags=re.IGNORECASE)
        html_content = re.sub(r'<link[^>]*>', '', html_content, flags=re.IGNORECASE) 
        
    return html_content

def extract_html_files(front_dir):
    """
    æå–å‰ç«¯ç›®å½•ä¸­çš„æ‰€æœ‰HTMLæ–‡ä»¶
    """
    html_files = []
    if os.path.exists(front_dir):
        for file in os.listdir(front_dir):
            if file.endswith('.html'):
                html_files.append(file)
    
    # æŒ‰æ–‡ä»¶åæ’åº
    html_files.sort()
    return html_files

def generate_frontend_sourcecode():
    """
    ç”Ÿæˆå‰ç«¯æºä»£ç æ–‡æ¡£
    """
    # å®šä¹‰è·¯å¾„ (è„šæœ¬ç§»åŠ¨åˆ°å­ç›®å½•åéœ€è¦è°ƒæ•´ç›¸å¯¹è·¯å¾„)
    base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))  # å›åˆ°é¡¹ç›®æ ¹ç›®å½•
    front_dir = os.path.join(base_dir, 'output_sourcecode', 'front')
    output_dir = os.path.join(base_dir, 'output_docs')
    output_file = os.path.join(output_dir, 'å‰ç«¯æºä»£ç .txt')
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–æ‰€æœ‰HTMLæ–‡ä»¶
    html_files = extract_html_files(front_dir)
    
    if not html_files:
        print(f"é”™è¯¯ï¼šåœ¨ {front_dir} ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°HTMLæ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶:")
    for file in html_files:
        print(f"  - {file}")
    
    # æ™ºèƒ½åˆ†æ‰¹å¤„ç†ä»¥é¿å…tokenè¶…é™
    print("\nğŸ” åˆ†ææ–‡ä»¶å¤§å°å¹¶æ™ºèƒ½åˆ†æ‰¹...")
    batches = split_content_by_token_limit(html_files, front_dir, max_tokens=25000)
    
    print(f"ğŸ“Š å°†ç”Ÿæˆ {len(batches)} ä¸ªæ–‡æ¡£æ–‡ä»¶:")
    for i, batch in enumerate(batches, 1):
        print(f"  æ‰¹æ¬¡ {i}: {len(batch)} ä¸ªæ–‡ä»¶")
    
    
    # å¼€å§‹ç”Ÿæˆæ–‡æ¡£
    print("\nğŸš€ å¼€å§‹ç”Ÿæˆå‰ç«¯æºä»£ç æ–‡æ¡£...")
    
    generated_files = []
    
    for batch_idx, batch in enumerate(batches, 1):
        # ä¸ºæ¯ä¸ªæ‰¹æ¬¡ç”Ÿæˆå•ç‹¬çš„æ–‡ä»¶
        if len(batches) == 1:
            batch_output_file = output_file
        else:
            batch_output_file = output_file.replace('.txt', f'_part{batch_idx}.txt')
        
        generated_files.append(batch_output_file)
        
        print(f"\nğŸ“ ç”Ÿæˆæ‰¹æ¬¡ {batch_idx}/{len(batches)} ({len(batch)} ä¸ªæ–‡ä»¶)")
        
        with open(batch_output_file, 'w', encoding='utf-8') as f:
            # å†™å…¥æ‰¹æ¬¡è¯´æ˜å¤´éƒ¨
            if len(batches) > 1:
                f.write(f"å‰ç«¯æºä»£ç æ–‡æ¡£ - ç¬¬ {batch_idx} éƒ¨åˆ†\n")
                f.write(f"åŒ…å«æ–‡ä»¶: {', '.join(batch)}\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"{'='*80}\n\n")
            
            total_tokens = 0
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡çš„æ¯ä¸ªHTMLæ–‡ä»¶
            for i, html_file in enumerate(batch, 1):
                file_path = os.path.join(front_dir, html_file)
                
                print(f"  å¤„ç†æ–‡ä»¶ {i}/{len(batch)}: {html_file}")
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as html_f:
                        html_content = html_f.read()
                    
                    # ç§»é™¤CSSå†…å®¹
                    html_content = remove_css_content(html_content)
                    
                    # å¦‚æœå†…å®¹ä»ç„¶è¿‡å¤§ï¼Œè¿›è¡Œå‹ç¼©
                    file_tokens = estimate_tokens(html_content)
                    if file_tokens > 15000:  # å•æ–‡ä»¶è¶…è¿‡15K tokensæ—¶å‹ç¼©
                        print(f"    âš ï¸  æ–‡ä»¶è¾ƒå¤§ï¼Œåº”ç”¨å‹ç¼© (~{file_tokens} tokens)")
                        html_content = compress_html_content(html_content, compression_level=2)
                        file_tokens = estimate_tokens(html_content)
                        print(f"    âœ… å‹ç¼©å ~{file_tokens} tokens")
                    
                    total_tokens += file_tokens
                    
                    # å†™å…¥æ–‡ä»¶åˆ†éš”æ ‡è¯†å’Œæºä»£ç 
                    f.write(f"=== {html_file} ===\n")
                    f.write(html_content)
                    f.write("\n\n")
                    
                except Exception as e:
                    print(f"    âŒ å¤„ç†æ–‡ä»¶ {html_file} æ—¶å‡ºé”™: {e}")
                    f.write(f"=== {html_file} ===\n")
                    f.write(f"é”™è¯¯ï¼šæ— æ³•è¯»å–æ–‡ä»¶å†…å®¹ - {e}\n\n")
            
            print(f"  ğŸ“Š æ‰¹æ¬¡ {batch_idx} é¢„ä¼°tokenæ•°: ~{total_tokens}")
    
    print(f"\nâœ… å‰ç«¯æºä»£ç æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼")
    if len(generated_files) == 1:
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {generated_files[0]}")
    else:
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶ ({len(generated_files)} ä¸ª):")
        for i, file_path in enumerate(generated_files, 1):
            print(f"  {i}. {file_path}")
    
    # æ˜¾ç¤ºæ–‡ä»¶å¤§å°ç»Ÿè®¡
    total_size = 0
    print(f"\nğŸ“Š æ–‡ä»¶å¤§å°ç»Ÿè®¡:")
    try:
        for i, file_path in enumerate(generated_files, 1):
            file_size = os.path.getsize(file_path)
            total_size += file_size
            
            if file_size > 1024 * 1024:
                size_str = f"{file_size / (1024 * 1024):.2f} MB"
            elif file_size > 1024:
                size_str = f"{file_size / 1024:.2f} KB"
            else:
                size_str = f"{file_size} bytes"
            
            if len(generated_files) > 1:
                print(f"  Part {i}: {size_str}")
            else:
                print(f"  æ€»å¤§å°: {size_str}")
        
        if len(generated_files) > 1:
            if total_size > 1024 * 1024:
                total_str = f"{total_size / (1024 * 1024):.2f} MB"
            elif total_size > 1024:
                total_str = f"{total_size / 1024:.2f} KB"
            else:
                total_str = f"{total_size} bytes"
            print(f"  ğŸ“Š æ€»è®¡: {total_str}")
            
    except Exception as e:
        print(f"  âš ï¸  æ— æ³•è·å–æ–‡ä»¶å¤§å°: {e}")
    
    # æ™ºèƒ½å»ºè®®
    if len(generated_files) > 1:
        print(f"\nğŸ’¡ å»ºè®®:")
        print(f"  â€¢ ç”Ÿæˆäº† {len(generated_files)} ä¸ªåˆ†æ®µæ–‡ä»¶ä»¥é¿å…tokenè¶…é™")
        print(f"  â€¢ åœ¨AIå¯¹è¯ä¸­å¯ä»¥åˆ†æ‰¹æ¬¡ç²˜è´´æ¯ä¸ªæ–‡ä»¶å†…å®¹")
        print(f"  â€¢ æˆ–è€…é€‰æ‹©æœ€é‡è¦çš„å‡ ä¸ªé¡µé¢å•ç‹¬å¤„ç†")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("=" * 60)
    print("å‰ç«¯æºä»£ç æ‹¼æ¥è„šæœ¬")
    print("=" * 60)
    
    try:
        generate_frontend_sourcecode()
    except Exception as e:
        print(f"âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())