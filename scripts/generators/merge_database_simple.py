#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®åº“æºä»£ç è½¯è‘—ç”³è¯·ä¸“ç”¨æ‹¼æ¥è„šæœ¬ (Pythonç‰ˆæœ¬)
åŠŸèƒ½ï¼šå°†æ‰€æœ‰æ•°æ®åº“ç›¸å…³æ–‡ä»¶å®Œæ•´æ‹¼æ¥æˆå•ä¸€æ–‡æ¡£ï¼Œä¸“ç”¨äºè½¯ä»¶è‘—ä½œæƒç”³è¯·ææ–™

ç‰¹ç‚¹ï¼š
- æ”¯æŒSQLæ–‡ä»¶ã€å»ºè¡¨è¯­å¥ã€å­˜å‚¨è¿‡ç¨‹ç­‰
- æ™ºèƒ½è¯†åˆ«æ•°æ®åº“æ–‡ä»¶ç±»å‹
- ä¿æŒSQLä»£ç æ ¼å¼å®Œæ•´æ€§
- è·¨å¹³å°å…¼å®¹ï¼ˆWindows/Linux/macOSï¼‰
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime
from typing import List, Optional, Dict

# é¢œè‰²è¾“å‡ºç±»
class Colors:
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    NC = '\033[0m'  # No Color

def print_success(message: str):
    print(f"{Colors.GREEN}âœ“ {message}{Colors.NC}")

def print_info(message: str):
    print(f"{Colors.BLUE}â„¹ {message}{Colors.NC}")

def print_warning(message: str):
    print(f"{Colors.YELLOW}âš  {message}{Colors.NC}")

def print_error(message: str):
    print(f"{Colors.RED}âœ— {message}{Colors.NC}")

def get_project_config() -> Optional[dict]:
    """è¯»å–é¡¹ç›®é…ç½®æ–‡ä»¶"""
    config_file = Path("ai-copyright-config.json")
    if not config_file.exists():
        print_error("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: ai-copyright-config.json")
        return None
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        print_error(f"é…ç½®æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {e}")
        return None
    except Exception as e:
        print_error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None

def collect_database_files(db_dir: Path) -> List[Path]:
    """æ”¶é›†æ‰€æœ‰æ•°æ®åº“ç›¸å…³æ–‡ä»¶"""
    if not db_dir.exists():
        return []
    
    # æ•°æ®åº“æ–‡ä»¶æ‰©å±•å
    db_extensions = {
        '.sql', '.ddl', '.dml', '.plsql', '.psql', 
        '.mysql', '.pgsql', '.sqlite', '.db',
        '.mdb', '.accdb', '.dbf'
    }
    
    db_files = []
    
    # é€’å½’æœç´¢æ•°æ®åº“æ–‡ä»¶
    for file_path in db_dir.rglob('*'):
        if file_path.is_file():
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæˆ–åŒ…å«SQLå…³é”®è¯çš„æ–‡ä»¶
            if (file_path.suffix.lower() in db_extensions or 
                'sql' in file_path.name.lower() or
                'database' in file_path.name.lower() or
                'schema' in file_path.name.lower()):
                
                if not should_exclude_file(file_path):
                    db_files.append(file_path)
    
    # æŒ‰ç›¸å¯¹è·¯å¾„æ’åºï¼Œç¡®ä¿ä¸€è‡´çš„è¾“å‡ºé¡ºåº
    db_files.sort(key=lambda x: str(x.relative_to(db_dir)).lower())
    return db_files

def should_exclude_file(file_path: Path) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ’é™¤æŸä¸ªæ–‡ä»¶"""
    exclude_patterns = [
        '.git',
        '.svn',
        '.log',
        '.tmp',
        '.temp',
        '.bak',
        '.backup'
    ]
    
    file_str = str(file_path).lower()
    for pattern in exclude_patterns:
        if pattern in file_str:
            return True
    
    # æ’é™¤ç©ºæ–‡ä»¶æˆ–è¿‡å¤§çš„æ–‡ä»¶
    try:
        file_size = file_path.stat().st_size
        if file_size == 0 or file_size > 50 * 1024 * 1024:  # 50MBé™åˆ¶
            return True
    except:
        return True
    
    return False

def read_database_file(file_path: Path) -> str:
    """å®‰å…¨è¯»å–æ•°æ®åº“æ–‡ä»¶å†…å®¹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        # å°è¯•å…¶ä»–ç¼–ç 
        encodings = ['gb2312', 'gbk', 'iso-8859-1', 'latin-1']
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    return f.read()
            except:
                continue
        
        print_warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path.name}: ç¼–ç é—®é¢˜")
        return f"-- æ–‡ä»¶è¯»å–å¤±è´¥: {file_path.name} (ç¼–ç é—®é¢˜)"
    except Exception as e:
        print_warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path.name}: {e}")
        return f"-- æ–‡ä»¶è¯»å–å¤±è´¥: {file_path.name}"

def analyze_sql_content(content: str) -> Dict[str, int]:
    """åˆ†æSQLå†…å®¹ï¼Œç»Ÿè®¡å„ç§è¯­å¥ç±»å‹"""
    content_upper = content.upper()
    stats = {
        'CREATE TABLE': content_upper.count('CREATE TABLE'),
        'CREATE VIEW': content_upper.count('CREATE VIEW'),
        'CREATE INDEX': content_upper.count('CREATE INDEX'),
        'CREATE PROCEDURE': content_upper.count('CREATE PROCEDURE'),
        'CREATE FUNCTION': content_upper.count('CREATE FUNCTION'),
        'INSERT INTO': content_upper.count('INSERT INTO'),
        'UPDATE': content_upper.count('UPDATE'),
        'DELETE FROM': content_upper.count('DELETE FROM'),
        'SELECT': content_upper.count('SELECT'),
        'ALTER TABLE': content_upper.count('ALTER TABLE'),
        'DROP TABLE': content_upper.count('DROP TABLE'),
    }
    return {k: v for k, v in stats.items() if v > 0}

def generate_header(config: dict, file_count: int) -> str:
    """ç”Ÿæˆæ–‡æ¡£å¤´éƒ¨ä¿¡æ¯"""
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    header = f"""
{'-' * 80}
è½¯ä»¶è‘—ä½œæƒç”³è¯·ææ–™ - æ•°æ®åº“æºä»£ç æ–‡æ¡£
{'-' * 80}

è½¯ä»¶åç§°: {config.get('title', 'æœªè®¾ç½®')}
è½¯ä»¶ç®€ç§°: {config.get('short_title', config.get('title', 'æœªè®¾ç½®'))}
åç«¯æŠ€æœ¯: {config.get('backend', 'æœªè®¾ç½®')}
ç”Ÿæˆæ¨¡å¼: {config.get('generation_mode', 'æœªè®¾ç½®')}

æ–‡æ¡£ç”Ÿæˆä¿¡æ¯:
- ç”Ÿæˆæ—¶é—´: {current_time}
- æ•°æ®åº“æ–‡ä»¶æ•°é‡: {file_count}
- æ–‡æ¡£ç±»å‹: æ•°æ®åº“è®¾è®¡å’Œå»ºè¡¨è¯­å¥
- ç¼–ç æ ¼å¼: UTF-8

{'-' * 80}
"""
    return header

def generate_footer() -> str:
    """ç”Ÿæˆæ–‡æ¡£å°¾éƒ¨ä¿¡æ¯"""
    footer = f"""

{'-' * 80}
æ–‡æ¡£ç»“æŸ
ç”Ÿæˆå·¥å…·: AIé©±åŠ¨çš„è½¯ä»¶è‘—ä½œæƒç”³è¯·ææ–™ç”Ÿæˆç³»ç»Ÿ (Pythonç‰ˆæœ¬)
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
{'-' * 80}
"""
    return footer

def merge_database_files():
    """ä¸»è¦çš„æ•°æ®åº“æ–‡ä»¶åˆå¹¶é€»è¾‘"""
    print_info("ğŸ”„ å¼€å§‹æ‹¼æ¥æ•°æ®åº“æºä»£ç ...")
    
    # 1. ç¡®å®šé¡¹ç›®æ ¹ç›®å½•
    script_dir = Path(__file__).parent.parent.parent
    db_dir = script_dir / "output_sourcecode" / "db"
    output_dir = script_dir / "output_docs"
    output_file = output_dir / "æ•°æ®åº“æºä»£ç .txt"
    
    print_info(f"é¡¹ç›®æ ¹ç›®å½•: {script_dir}")
    print_info(f"æ•°æ®åº“ç›®å½•: {db_dir}")
    print_info(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    # 2. æ£€æŸ¥æ•°æ®åº“ç›®å½•
    if not db_dir.exists():
        print_error(f"æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨: {db_dir}")
        print_info("ğŸ’¡ è¯·å…ˆç”Ÿæˆæ•°æ®åº“æºä»£ç æ–‡ä»¶")
        return False
    
    # 3. ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 4. è¯»å–é¡¹ç›®é…ç½®
    config = get_project_config()
    if not config:
        print_warning("æ— æ³•è¯»å–é¡¹ç›®é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        config = {
            'title': 'è½¯ä»¶ç³»ç»Ÿ',
            'short_title': 'è½¯ä»¶ç³»ç»Ÿ',
            'backend': 'Java',
            'generation_mode': 'fast'
        }
    
    # 5. æ”¶é›†æ•°æ®åº“æ–‡ä»¶
    db_files = collect_database_files(db_dir)
    if not db_files:
        print_error(f"åœ¨ {db_dir} ä¸­æœªå‘ç°æ•°æ®åº“æ–‡ä»¶")
        print_info("ğŸ’¡ è¯·å…ˆç”Ÿæˆæ•°æ®åº“æºä»£ç æ–‡ä»¶")
        return False
    
    print_success(f"å‘ç° {len(db_files)} ä¸ªæ•°æ®åº“æ–‡ä»¶")
    
    # 6. æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç»„ç»Ÿè®¡
    file_stats = {}
    for file_path in db_files:
        ext = file_path.suffix.lower() or '(æ— æ‰©å±•å)'
        if ext not in file_stats:
            file_stats[ext] = 0
        file_stats[ext] += 1
    
    print_info("æ–‡ä»¶ç±»å‹ç»Ÿè®¡:")
    for ext, count in sorted(file_stats.items()):
        print_info(f"  {ext}: {count} ä¸ªæ–‡ä»¶")
    
    # 7. å¼€å§‹åˆå¹¶æ–‡ä»¶
    total_sql_stats = {}
    
    try:
        with open(output_file, 'w', encoding='utf-8') as output:
            # å†™å…¥æ–‡æ¡£å¤´éƒ¨
            output.write(generate_header(config, len(db_files)))
            
            # é€ä¸ªå¤„ç†æ•°æ®åº“æ–‡ä»¶
            for i, db_file in enumerate(db_files, 1):
                rel_path = db_file.relative_to(db_dir)
                print_info(f"å¤„ç†æ–‡ä»¶ {i}/{len(db_files)}: {rel_path}")
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = read_database_file(db_file)
                
                # åˆ†æSQLå†…å®¹
                sql_stats = analyze_sql_content(content)
                for stmt_type, count in sql_stats.items():
                    if stmt_type not in total_sql_stats:
                        total_sql_stats[stmt_type] = 0
                    total_sql_stats[stmt_type] += count
                
                # æ·»åŠ æ–‡ä»¶åˆ†éš”æ ‡è¯†
                separator = f"""
{'=' * 80}
æ–‡ä»¶ {i}: {db_file.name}
æ–‡ä»¶è·¯å¾„: output_sourcecode/db/{rel_path}
æ–‡ä»¶ç±»å‹: {db_file.suffix or '(æ— æ‰©å±•å)'}
æ–‡ä»¶å¤§å°: {db_file.stat().st_size} å­—èŠ‚
{'=' * 80}

"""
                output.write(separator)
                
                # å¦‚æœæœ‰SQLç»Ÿè®¡ä¿¡æ¯ï¼Œæ·»åŠ åˆ°åˆ†éš”ç¬¦ä¸­
                if sql_stats:
                    output.write("SQLè¯­å¥ç»Ÿè®¡:\n")
                    for stmt_type, count in sql_stats.items():
                        output.write(f"  {stmt_type}: {count}\n")
                    output.write("\n")
                
                # å†™å…¥æ–‡ä»¶å†…å®¹
                output.write(content)
                
                # ç¡®ä¿æ–‡ä»¶å†…å®¹ä»¥æ¢è¡Œç»“æŸ
                if content and not content.endswith('\n'):
                    output.write('\n')
                
                # æ·»åŠ æ–‡ä»¶ç»“æŸæ ‡è¯†
                output.write(f"\n\n{'=' * 80}\næ–‡ä»¶ {i} ç»“æŸ: {db_file.name}\n{'=' * 80}\n\n")
            
            # å†™å…¥æ€»ä½“SQLç»Ÿè®¡
            if total_sql_stats:
                output.write(f"""
{'-' * 80}
æ•´ä½“SQLè¯­å¥ç»Ÿè®¡
{'-' * 80}

""")
                for stmt_type, count in sorted(total_sql_stats.items()):
                    output.write(f"{stmt_type}: {count}\n")
                output.write(f"\n{'-' * 80}\n")
            
            # å†™å…¥æ–‡æ¡£å°¾éƒ¨
            output.write(generate_footer())
        
        # 8. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        file_size = output_file.stat().st_size
        file_size_mb = file_size / (1024 * 1024)
        
        print_success("âœ… æ•°æ®åº“æºä»£ç æ‹¼æ¥å®Œæˆ")
        print_info(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print_info(f"ğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
        print_info(f"   - æ•°æ®åº“æ–‡ä»¶æ•°é‡: {len(db_files)}")
        print_info(f"   - æ€»æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚ ({file_size_mb:.2f} MB)")
        
        if total_sql_stats:
            print_info("ğŸ“Š SQLè¯­å¥ç»Ÿè®¡:")
            for stmt_type, count in sorted(total_sql_stats.items()):
                print_info(f"   - {stmt_type}: {count}")
        
        # 9. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        with open(output_dir / "æ•°æ®åº“æ‹¼æ¥æŠ¥å‘Š.txt", 'w', encoding='utf-8') as report:
            report.write(f"æ•°æ®åº“æºä»£ç æ‹¼æ¥æŠ¥å‘Š\n")
            report.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            report.write(f"æ–‡ä»¶ç±»å‹ç»Ÿè®¡:\n")
            for ext, count in sorted(file_stats.items()):
                report.write(f"  {ext}: {count} ä¸ªæ–‡ä»¶\n")
            
            if total_sql_stats:
                report.write(f"\nSQLè¯­å¥ç»Ÿè®¡:\n")
                for stmt_type, count in sorted(total_sql_stats.items()):
                    report.write(f"  {stmt_type}: {count}\n")
            
            report.write(f"\næ–‡ä»¶åˆ—è¡¨:\n")
            for i, db_file in enumerate(db_files, 1):
                rel_path = db_file.relative_to(db_dir)
                file_size = db_file.stat().st_size
                report.write(f"{i:3d}. {rel_path} ({file_size:,} å­—èŠ‚)\n")
            
            total_size = sum(f.stat().st_size for f in db_files)
            report.write(f"\næ€»è®¡: {len(db_files)} ä¸ªæ–‡ä»¶ï¼Œ{total_size:,} å­—èŠ‚\n")
        
        print_success("ğŸ“‹ ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š: æ•°æ®åº“æ‹¼æ¥æŠ¥å‘Š.txt")
        return True
        
    except Exception as e:
        print_error(f"æ–‡ä»¶åˆå¹¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1 and sys.argv[1] in ['-h', '--help']:
        print("æ•°æ®åº“æºä»£ç æ‹¼æ¥è„šæœ¬ (Pythonç‰ˆæœ¬)")
        print("\nç”¨æ³•:")
        print("  python3 merge_database_simple.py")
        print("\nè¯´æ˜:")
        print("  å°† output_sourcecode/db/ ç›®å½•ä¸‹çš„æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶")
        print("  æ‹¼æ¥æˆå•ä¸€çš„æºä»£ç æ–‡æ¡£ç”¨äºè½¯è‘—ç”³è¯·")
        print("\næ”¯æŒçš„æ–‡ä»¶ç±»å‹:")
        print("  - .sql, .ddl, .dml - SQLè„šæœ¬æ–‡ä»¶")
        print("  - .plsql, .psql - å­˜å‚¨è¿‡ç¨‹æ–‡ä»¶") 
        print("  - .mysql, .pgsql - æ•°æ®åº“ç‰¹å®šæ–‡ä»¶")
        print("  - database_schema.sql - å»ºè¡¨è¯­å¥")
        print("\nè¾“å‡º:")
        print("  output_docs/æ•°æ®åº“æºä»£ç .txt")
        print("  output_docs/æ•°æ®åº“æ‹¼æ¥æŠ¥å‘Š.txt")
        return
    
    success = merge_database_files()
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()